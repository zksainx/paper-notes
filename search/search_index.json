{"config":{"lang":["zh","en"],"separator":"[\\s\\-\\.]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\u6b22\u8fce\u6765\u5230\u8bba\u6587\u7b14\u8bb0","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bb0\u5f55\u548c\u6574\u7406\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0\u7684\u4e2a\u4eba\u77e5\u8bc6\u5e93\u3002</p>"},{"location":"#_2","title":"\ud83c\udfaf \u7f51\u7ad9\u7b80\u4ecb","text":"<p>\u672c\u7ad9\u70b9\u8bb0\u5f55\u4e86\u6211\u5728\u4eba\u5de5\u667a\u80fd\u3001\u673a\u5668\u5b66\u4e60\u7b49\u9886\u57df\u7684\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0\u3002\u6bcf\u7bc7\u7b14\u8bb0\u5305\u542b\u8bba\u6587\u7684\u6838\u5fc3\u601d\u60f3\u3001\u65b9\u6cd5\u603b\u7ed3\u3001\u5b9e\u9a8c\u7ed3\u679c\u5206\u6790\u4ee5\u53ca\u4e2a\u4eba\u601d\u8003\u3002</p>"},{"location":"#_3","title":"\ud83d\udcda \u5185\u5bb9\u5206\u7c7b","text":"<p>\u7f51\u7ad9\u6309\u7814\u7a76\u9886\u57df\u7ec4\u7ec7\u8bba\u6587\u7b14\u8bb0\uff1a</p>"},{"location":"#_4","title":"\u673a\u5668\u5b66\u4e60","text":"<p>\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u3001\u4f18\u5316\u65b9\u6cd5\u3001\u6a21\u578b\u67b6\u6784\u7b49\u76f8\u5173\u8bba\u6587\u3002</p>"},{"location":"#_5","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":"<p>\u6db5\u76d6\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u56fe\u50cf\u5206\u5272\u3001\u751f\u6210\u6a21\u578b\u7b49\u89c6\u89c9\u4efb\u52a1\u7684\u8bba\u6587\u3002</p>"},{"location":"#_6","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406","text":"<p>\u5305\u542b\u8bed\u8a00\u6a21\u578b\u3001\u6587\u672c\u7406\u89e3\u3001\u673a\u5668\u7ffb\u8bd1\u7b49NLP\u9886\u57df\u7684\u8bba\u6587\u3002</p>"},{"location":"#_7","title":"\ud83d\udd0d \u5982\u4f55\u4f7f\u7528","text":"<ul> <li>\u6d4f\u89c8\u5206\u7c7b\uff1a\u70b9\u51fb\u9876\u90e8\u5bfc\u822a\u680f\u9009\u62e9\u611f\u5174\u8da3\u7684\u7814\u7a76\u9886\u57df</li> <li>\u641c\u7d22\u8bba\u6587\uff1a\u4f7f\u7528\u53f3\u4e0a\u89d2\u7684\u641c\u7d22\u6846\u5feb\u901f\u67e5\u627e\u7279\u5b9a\u8bba\u6587\u6216\u5173\u952e\u8bcd</li> <li>\u9605\u8bfb\u7b14\u8bb0\uff1a\u6bcf\u7bc7\u7b14\u8bb0\u5305\u542b\u8bba\u6587\u6458\u8981\u3001\u6838\u5fc3\u601d\u60f3\u3001\u65b9\u6cd5\u4ecb\u7ecd\u548c\u4e2a\u4eba\u7406\u89e3</li> </ul>"},{"location":"#_8","title":"\ud83d\udcdd \u7b14\u8bb0\u6a21\u677f","text":"<p>\u6bcf\u7bc7\u8bba\u6587\u7b14\u8bb0\u901a\u5e38\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li>\u8bba\u6587\u57fa\u672c\u4fe1\u606f\uff08\u6807\u9898\u3001\u4f5c\u8005\u3001\u4f1a\u8bae/\u671f\u520a\u3001\u5e74\u4efd\uff09</li> <li>\u6458\u8981\uff1a\u8bba\u6587\u8981\u89e3\u51b3\u7684\u95ee\u9898\u548c\u4e3b\u8981\u8d21\u732e</li> <li>\u6838\u5fc3\u601d\u60f3\uff1a\u8bba\u6587\u7684\u5173\u952e\u521b\u65b0\u70b9</li> <li>\u65b9\u6cd5\uff1a\u6280\u672f\u7ec6\u8282\u548c\u5b9e\u73b0\u65b9\u5f0f</li> <li>\u5b9e\u9a8c\u7ed3\u679c\uff1a\u4e3b\u8981\u5b9e\u9a8c\u7ed3\u8bba</li> <li>\u4e2a\u4eba\u7b14\u8bb0\uff1a\u4e2a\u4eba\u601d\u8003\u3001\u7591\u95ee\u548c\u5ef6\u4f38\u9605\u8bfb</li> </ul>"},{"location":"#_9","title":"\ud83d\ude80 \u66f4\u65b0\u65e5\u5fd7","text":"<p>\u672c\u7f51\u7ad9\u4f1a\u6301\u7eed\u66f4\u65b0\uff0c\u8bb0\u5f55\u6700\u65b0\u9605\u8bfb\u7684\u8bba\u6587\u3002\u6b22\u8fce\u8bbf\u95ee GitHub \u4ed3\u5e93 \u67e5\u770b\u66f4\u65b0\u5386\u53f2\u3002</p> <p>\u6700\u540e\u66f4\u65b0\uff1a2024\u5e74</p>"},{"location":"about/","title":"\u5173\u4e8e\u672c\u7ad9","text":""},{"location":"about/#_2","title":"\ud83c\udf93 \u5173\u4e8e\u4f5c\u8005","text":"<p>\u6211\u662f\u4e00\u540d\u5bf9\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u5145\u6ee1\u70ed\u60c5\u7684\u7814\u7a76\u8005/\u5b66\u4e60\u8005\u3002\u8fd9\u4e2a\u7f51\u7ad9\u662f\u6211\u6574\u7406\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0\u3001\u6c89\u6dc0\u77e5\u8bc6\u7684\u4e2a\u4eba\u7a7a\u95f4\u3002</p>"},{"location":"about/#_3","title":"\ud83d\udca1 \u521b\u5efa\u521d\u8877","text":"<p>\u5728\u9605\u8bfb\u5927\u91cf\u8bba\u6587\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6211\u53d1\u73b0\uff1a</p> <ul> <li>\u8bba\u6587\u6570\u91cf\u591a\uff0c\u5bb9\u6613\u9057\u5fd8\u4e4b\u524d\u8bfb\u8fc7\u7684\u5185\u5bb9</li> <li>\u7f3a\u5c11\u7cfb\u7edf\u5316\u7684\u6574\u7406\uff0c\u96be\u4ee5\u5efa\u7acb\u77e5\u8bc6\u4f53\u7cfb</li> <li>\u597d\u7684\u60f3\u6cd5\u548c\u542f\u53d1\u9700\u8981\u8bb0\u5f55\u4e0b\u6765</li> </ul> <p>\u56e0\u6b64\u521b\u5efa\u4e86\u8fd9\u4e2a\u7f51\u7ad9\uff0c\u5e0c\u671b\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u7b14\u8bb0\u8bb0\u5f55\uff1a</p> <ol> <li>\u52a0\u6df1\u7406\u89e3\uff1a\u901a\u8fc7\u6574\u7406\u7b14\u8bb0\u5f3a\u5316\u5bf9\u8bba\u6587\u7684\u7406\u89e3</li> <li>\u77e5\u8bc6\u6c89\u6dc0\uff1a\u6784\u5efa\u4e2a\u4eba\u7684\u77e5\u8bc6\u5e93\uff0c\u65b9\u4fbf\u65e5\u540e\u67e5\u9605</li> <li>\u601d\u7ef4\u78b0\u649e\uff1a\u8bb0\u5f55\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u7684\u601d\u8003\u548c\u542f\u53d1</li> </ol>"},{"location":"about/#_4","title":"\ud83d\udee0\ufe0f \u6280\u672f\u6808","text":"<p>\u672c\u7ad9\u70b9\u4f7f\u7528\u4ee5\u4e0b\u6280\u672f\u6784\u5efa\uff1a</p> <ul> <li>MkDocs\uff1a\u9759\u6001\u7ad9\u70b9\u751f\u6210\u5668</li> <li>Material for MkDocs\uff1a\u73b0\u4ee3\u5316\u7684\u4e3b\u9898</li> <li>GitHub Pages\uff1a\u514d\u8d39\u6258\u7ba1</li> <li>GitHub Actions\uff1a\u81ea\u52a8\u5316\u90e8\u7f72</li> </ul>"},{"location":"about/#_5","title":"\ud83d\udcd6 \u7b14\u8bb0\u89c4\u8303","text":"<p>\u4e3a\u4e86\u4fdd\u6301\u7b14\u8bb0\u7684\u4e00\u81f4\u6027\u548c\u53ef\u8bfb\u6027\uff0c\u6211\u9075\u5faa\u4ee5\u4e0b\u89c4\u8303\uff1a</p> <ul> <li>\u5ba2\u89c2\u8bb0\u5f55\uff1a\u51c6\u786e\u8bb0\u5f55\u8bba\u6587\u5185\u5bb9\uff0c\u4e0d\u6b6a\u66f2\u539f\u610f</li> <li>\u7ed3\u6784\u6e05\u6670\uff1a\u4f7f\u7528\u7edf\u4e00\u7684\u6a21\u677f\u7ec4\u7ec7\u5185\u5bb9</li> <li>\u91cd\u70b9\u7a81\u51fa\uff1a\u6807\u6ce8\u6838\u5fc3\u8d21\u732e\u548c\u5173\u952e\u521b\u65b0</li> <li>\u4e2a\u4eba\u601d\u8003\uff1a\u533a\u5206\u8bba\u6587\u5185\u5bb9\u548c\u4e2a\u4eba\u7406\u89e3</li> </ul>"},{"location":"about/#_6","title":"\ud83d\udd17 \u76f8\u5173\u94fe\u63a5","text":"<ul> <li>GitHub \u4ed3\u5e93</li> <li>\u4e2a\u4eba\u4e3b\u9875</li> <li>\u8054\u7cfb\u65b9\u5f0f</li> </ul>"},{"location":"about/#_7","title":"\ud83d\udcc4 \u8bb8\u53ef\u534f\u8bae","text":"<p>\u672c\u7ad9\u70b9\u7684\u6240\u6709\u539f\u521b\u5185\u5bb9\u91c7\u7528 CC BY-NC-SA 4.0 \u8bb8\u53ef\u534f\u8bae\u3002</p> <p>\u8bba\u6587\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u672c\u7ad9\u4ec5\u63d0\u4f9b\u5b66\u4e60\u7b14\u8bb0\u548c\u4e2a\u4eba\u7406\u89e3\u3002</p> <p>\u5982\u6709\u4efb\u4f55\u95ee\u9898\u6216\u5efa\u8bae\uff0c\u6b22\u8fce\u901a\u8fc7 GitHub Issues \u8054\u7cfb\u6211\uff01</p>"},{"location":"computer-vision/","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":"<p>\u672c\u5206\u7c7b\u6536\u5f55\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u7ecf\u5178\u8bba\u6587\u548c\u524d\u6cbf\u7814\u7a76\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a</p> <ul> <li>\u56fe\u50cf\u5206\u7c7b</li> <li>\u76ee\u6807\u68c0\u6d4b\u4e0e\u5206\u5272</li> <li>\u751f\u6210\u6a21\u578b\uff08GAN\u3001Diffusion\uff09</li> <li>\u89c6\u89c9\u8868\u793a\u5b66\u4e60</li> <li>\u591a\u6a21\u6001\u5b66\u4e60</li> <li>3D \u89c6\u89c9</li> </ul>"},{"location":"computer-vision/#_2","title":"\ud83d\udcd1 \u8bba\u6587\u5217\u8868","text":""},{"location":"computer-vision/#_3","title":"\u7ecf\u5178\u7f51\u7edc\u67b6\u6784","text":"<ul> <li>ResNet: Deep Residual Learning for Image Recognition - Microsoft Research, CVPR 2016</li> <li>\u63d0\u51fa\u6b8b\u5dee\u8fde\u63a5\u89e3\u51b3\u6df1\u5ea6\u7f51\u7edc\u9000\u5316\u95ee\u9898\uff0c\u4f7f\u8bad\u7ec3\u6781\u6df1\u7f51\u7edc\u6210\u4e3a\u53ef\u80fd</li> </ul> <p>\u6301\u7eed\u66f4\u65b0\u4e2d...</p>"},{"location":"computer-vision/resnet/","title":"Deep Residual Learning for Image Recognition (ResNet)","text":"<p>\u4f5c\u8005: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun \u673a\u6784: Microsoft Research \u4f1a\u8bae: CVPR 2016 \u8bba\u6587\u94fe\u63a5: arXiv:1512.03385</p> <p>ResNet \u6b8b\u5dee\u8fde\u63a5 \u56fe\u50cf\u5206\u7c7b \u6df1\u5ea6\u7f51\u7edc</p>"},{"location":"computer-vision/resnet/#_1","title":"\ud83d\udcdd \u6458\u8981","text":"<p>\u672c\u6587\u63d0\u51fa\u4e86\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60\u6846\u67b6\uff08ResNet\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u6b8b\u5dee\u8fde\u63a5\uff08skip connection\uff09\u89e3\u51b3\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9000\u5316\u95ee\u9898\u3002ResNet \u5728 ImageNet \u5206\u7c7b\u3001COCO \u68c0\u6d4b\u548c\u5206\u5272\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u5e76\u8d62\u5f97\u4e86 ILSVRC 2015 \u56fe\u50cf\u5206\u7c7b\u51a0\u519b\u3002</p> <p>\u4e3b\u8981\u8d21\u732e\uff1a - \u63d0\u51fa\u6b8b\u5dee\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u8bad\u7ec3\u8d85\u8fc7 100 \u5c42\u7684\u7f51\u7edc\u6210\u4e3a\u53ef\u80fd - \u5728 ImageNet \u4e0a\u4ee5 152 \u5c42\u7f51\u7edc\u8fbe\u5230 3.57% top-5 \u9519\u8bef\u7387 - \u8bc1\u660e\u4e86\u6781\u6df1\u7f51\u7edc\u7684\u6709\u6548\u6027</p>"},{"location":"computer-vision/resnet/#_2","title":"\ud83d\udca1 \u6838\u5fc3\u601d\u60f3","text":""},{"location":"computer-vision/resnet/#degradation-problem","title":"\u9000\u5316\u95ee\u9898\uff08Degradation Problem\uff09","text":"<p>\u5b9e\u9a8c\u53d1\u73b0\uff0c\u7b80\u5355\u5730\u5806\u53e0\u66f4\u591a\u5c42\u4f1a\u5bfc\u81f4\u9000\u5316\uff1a\u66f4\u6df1\u7684\u7f51\u7edc\u8bad\u7ec3\u8bef\u5dee\u53cd\u800c\u66f4\u9ad8\uff08\u4e0d\u662f\u8fc7\u62df\u5408\uff09\u3002</p>"},{"location":"computer-vision/resnet/#residual-learning","title":"\u6b8b\u5dee\u5b66\u4e60\uff08Residual Learning\uff09","text":"<p>\u4e0e\u5176\u5b66\u4e60\u76f4\u63a5\u6620\u5c04 \\(H(x)\\)\uff0c\u4e0d\u5982\u5b66\u4e60\u6b8b\u5dee\u6620\u5c04\uff1a</p> \\[ F(x) = H(x) - x \\] <p>\u539f\u59cb\u6620\u5c04\u53d8\u4e3a\uff1a</p> \\[ H(x) = F(x) + x \\] <p>\u76f4\u89c9\uff1a\u5b66\u4e60\"\u5982\u4f55\u8c03\u6574\"\u6bd4\u5b66\u4e60\"\u5b8c\u6574\u8f93\u51fa\"\u66f4\u5bb9\u6613\u3002</p>"},{"location":"computer-vision/resnet/#residual-block","title":"\u6b8b\u5dee\u5757\uff08Residual Block\uff09","text":"<pre><code>x \u2192 [Conv-BN-ReLU-Conv-BN] \u2192 F(x)\n \u2193                              \u2193\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 (+) \u2192 ReLU \u2192 output\n           identity\n</code></pre>"},{"location":"computer-vision/resnet/#_3","title":"\ud83c\udfd7\ufe0f \u7f51\u7edc\u67b6\u6784","text":""},{"location":"computer-vision/resnet/#resnet-50101152","title":"ResNet-50/101/152","text":"\u5c42\u540d \u8f93\u51fa\u5c3a\u5bf8 ResNet-50 ResNet-101 ResNet-152 conv1 112\u00d7112 7\u00d77, 64, stride 2 7\u00d77, 64, stride 2 7\u00d77, 64, stride 2 conv2_x 56\u00d756 3\u00d73 max pool, stride 2[1\u00d71,643\u00d73,641\u00d71,256] \u00d73 \u00d73 \u00d73 conv3_x 28\u00d728 [1\u00d71,1283\u00d73,1281\u00d71,512] \u00d74 \u00d74 \u00d78 conv4_x 14\u00d714 [1\u00d71,2563\u00d73,2561\u00d71,1024] \u00d76 \u00d723 \u00d736 conv5_x 7\u00d77 [1\u00d71,5123\u00d73,5121\u00d71,2048] \u00d73 \u00d73 \u00d73 1\u00d71 average pool, 1000-d fc, softmax"},{"location":"computer-vision/resnet/#bottleneck","title":"\u74f6\u9888\u7ed3\u6784\uff08Bottleneck\uff09","text":"<p>\u4e3a\u4e86\u964d\u4f4e\u8ba1\u7b97\u91cf\uff0cResNet-50/101/152 \u4f7f\u7528\u74f6\u9888\u8bbe\u8ba1\uff1a</p> <pre><code>1\u00d71 conv (\u964d\u7ef4) \u2192 3\u00d73 conv \u2192 1\u00d71 conv (\u5347\u7ef4)\n</code></pre>"},{"location":"computer-vision/resnet/#_4","title":"\ud83d\udcca \u5b9e\u9a8c\u7ed3\u679c","text":""},{"location":"computer-vision/resnet/#imagenet","title":"ImageNet \u5206\u7c7b","text":"\u6a21\u578b Top-1 Error Top-5 Error \u53c2\u6570\u91cf VGG-16 - 7.3% 138M GoogleNet - 6.7% - ResNet-34 24.5% - 21.8M ResNet-50 22.9% - 25.6M ResNet-101 21.8% - 44.5M ResNet-152 21.4% 3.57% 60.2M"},{"location":"computer-vision/resnet/#coco","title":"COCO \u76ee\u6807\u68c0\u6d4b","text":"<p>\u57fa\u4e8e Faster R-CNN + ResNet-101\uff1a</p> <ul> <li>mAP: \u63d0\u5347 6% \u76f8\u6bd4 VGG-16</li> </ul>"},{"location":"computer-vision/resnet/#_5","title":"\u6d88\u878d\u5b9e\u9a8c","text":"<p>\u6052\u7b49\u6620\u5c04 vs \u6295\u5f71\uff1a - \u6052\u7b49 shortcut \u6548\u679c\u6700\u597d - \u6295\u5f71 shortcut \u7565\u6709\u63d0\u5347\u4f46\u589e\u52a0\u53c2\u6570</p> <p>\u7f51\u7edc\u6df1\u5ea6\uff1a - 18\u5c42 \u2192 34\u5c42\uff1a\u9519\u8bef\u7387\u663e\u8457\u4e0b\u964d - 50\u5c42 \u2192 101\u5c42 \u2192 152\u5c42\uff1a\u6301\u7eed\u6539\u8fdb</p>"},{"location":"computer-vision/resnet/#_6","title":"\ud83e\udd14 \u4e2a\u4eba\u7b14\u8bb0","text":""},{"location":"computer-vision/resnet/#_7","title":"\u4e3a\u4ec0\u4e48\u6b8b\u5dee\u8fde\u63a5\u6709\u6548\uff1f","text":"<ol> <li>\u68af\u5ea6\u6d41\u52a8\uff1ashortcut \u63d0\u4f9b\u4e86\u68af\u5ea6\u7684\u76f4\u63a5\u901a\u8def\uff0c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931</li> <li>\u96c6\u6210\u6548\u5e94\uff1a\u7f51\u7edc\u53ef\u4ee5\u770b\u4f5c\u591a\u4e2a\u6d45\u5c42\u7f51\u7edc\u7684\u96c6\u6210</li> <li>\u4f18\u5316\u666f\u89c2\uff1a\u6b8b\u5dee\u5b66\u4e60\u4f7f\u635f\u5931\u51fd\u6570\u66f4\u5e73\u6ed1\uff0c\u66f4\u5bb9\u6613\u4f18\u5316</li> </ol>"},{"location":"computer-vision/resnet/#_8","title":"\u8bbe\u8ba1\u8981\u70b9","text":"<ul> <li>\u6279\u5f52\u4e00\u5316\uff08BN\uff09\uff1a\u6bcf\u4e2a\u5377\u79ef\u540e\u90fd\u4f7f\u7528 BN</li> <li>\u65e0 Dropout\uff1aResNet \u4e0d\u4f7f\u7528 dropout</li> <li>\u6570\u636e\u589e\u5f3a\uff1a\u6807\u51c6\u7684\u88c1\u526a\u3001\u7ffb\u8f6c\u3001\u989c\u8272\u6296\u52a8</li> </ul>"},{"location":"computer-vision/resnet/#_9","title":"\u540e\u7eed\u53d1\u5c55","text":"<ul> <li>ResNeXt\uff1a\u5f15\u5165\u5206\u7ec4\u5377\u79ef\uff0c\u63d0\u5347\u8868\u793a\u80fd\u529b</li> <li>DenseNet\uff1a\u5bc6\u96c6\u8fde\u63a5\uff0c\u8fdb\u4e00\u6b65\u52a0\u5f3a\u7279\u5f81\u590d\u7528</li> <li>EfficientNet\uff1a\u901a\u8fc7 NAS \u81ea\u52a8\u641c\u7d22\u9ad8\u6548\u67b6\u6784</li> <li>ResNet \u53d8\u4f53\uff1aPre-activation ResNet\u3001Wide ResNet \u7b49</li> </ul>"},{"location":"computer-vision/resnet/#_10","title":"\u5f71\u54cd","text":"<p>ResNet \u7684\u6b8b\u5dee\u8fde\u63a5\u601d\u60f3\u5f71\u54cd\u6df1\u8fdc\uff1a</p> <ul> <li>Transformer\uff1a\u4e5f\u4f7f\u7528\u6b8b\u5dee\u8fde\u63a5</li> <li>\u76ee\u6807\u68c0\u6d4b\uff1aFPN\u3001Mask R-CNN \u7b49\u90fd\u57fa\u4e8e ResNet</li> <li>\u5de5\u4e1a\u5e94\u7528\uff1aResNet \u6210\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u6807\u51c6\u9aa8\u5e72\u7f51\u7edc</li> </ul>"},{"location":"computer-vision/resnet/#_11","title":"\ud83d\udd17 \u76f8\u5173\u8bba\u6587","text":"<ul> <li>VGG: Very Deep Convolutional Networks - \u66f4\u65e9\u7684\u6df1\u5ea6\u7f51\u7edc\u5c1d\u8bd5</li> <li>Inception/GoogleNet: Going Deeper with Convolutions - \u591a\u5c3a\u5ea6\u5377\u79ef</li> <li>ResNeXt: Aggregated Residual Transformations - ResNet \u6539\u8fdb</li> <li>DenseNet: Densely Connected Convolutional Networks - \u5bc6\u96c6\u8fde\u63a5</li> </ul>"},{"location":"computer-vision/resnet/#_12","title":"\ud83d\udccc \u5173\u952e\u4ee3\u7801\u7247\u6bb5","text":"<pre><code>import torch\nimport torch.nn as nn\n\nclass BasicBlock(nn.Module):\n    \"\"\"ResNet-18/34 \u7684\u57fa\u672c\u6b8b\u5dee\u5757\"\"\"\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = torch.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    \"\"\"ResNet-50/101/152 \u7684\u74f6\u9888\u6b8b\u5dee\u5757\"\"\"\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, 1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels * 4:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels * 4, 1, stride, bias=False),\n                nn.BatchNorm2d(out_channels * 4)\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = torch.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = torch.relu(out)\n        return out\n</code></pre> <p>\u9605\u8bfb\u65e5\u671f\uff1a2024\u5e74 \u7b14\u8bb0\u72b6\u6001\uff1a\u5df2\u5b8c\u6210</p>"},{"location":"machine-learning/","title":"\u673a\u5668\u5b66\u4e60","text":"<p>\u672c\u5206\u7c7b\u6536\u5f55\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7ecf\u5178\u8bba\u6587\u548c\u524d\u6cbf\u7814\u7a76\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a</p> <ul> <li>\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u7406\u8bba</li> <li>\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1</li> <li>\u4f18\u5316\u7b97\u6cd5\u4e0e\u8bad\u7ec3\u6280\u5de7</li> <li>\u8868\u793a\u5b66\u4e60\u4e0e\u7279\u5f81\u63d0\u53d6</li> <li>\u8fc1\u79fb\u5b66\u4e60\u4e0e\u5143\u5b66\u4e60</li> <li>\u5f3a\u5316\u5b66\u4e60</li> </ul>"},{"location":"machine-learning/#_2","title":"\ud83d\udcd1 \u8bba\u6587\u5217\u8868","text":""},{"location":"machine-learning/#transformer","title":"\u6ce8\u610f\u529b\u673a\u5236\u4e0eTransformer","text":"<ul> <li>Attention Is All You Need - Google, NeurIPS 2017</li> <li>\u63d0\u51fa\u4e86\u5b8c\u5168\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684Transformer\u67b6\u6784\uff0c\u5f00\u542f\u4e86NLP\u9886\u57df\u7684\u65b0\u7eaa\u5143</li> </ul> <p>\u6301\u7eed\u66f4\u65b0\u4e2d...</p>"},{"location":"machine-learning/attention-is-all-you-need/","title":"Attention Is All You Need","text":"<p>\u4f5c\u8005: Ashish Vaswani, Noam Shazeer, Niki Parmar, et al. \u673a\u6784: Google Brain, Google Research \u4f1a\u8bae: NeurIPS 2017 \u8bba\u6587\u94fe\u63a5: arXiv:1706.03762</p> <p>Transformer \u6ce8\u610f\u529b\u673a\u5236 \u5e8f\u5217\u5efa\u6a21</p>"},{"location":"machine-learning/attention-is-all-you-need/#_1","title":"\ud83d\udcdd \u6458\u8981","text":"<p>\u672c\u6587\u63d0\u51fa\u4e86 Transformer \u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b8c\u5168\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u5e8f\u5217\u8f6c\u6362\u6a21\u578b\uff0c\u6452\u5f03\u4e86\u5faa\u73af\u548c\u5377\u79ef\u7ed3\u6784\u3002\u5728\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u4e0a\uff0cTransformer \u4e0d\u4ec5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u800c\u4e14\u8bad\u7ec3\u901f\u5ea6\u663e\u8457\u63d0\u5347\u3002</p> <p>\u4e3b\u8981\u8d21\u732e\uff1a - \u63d0\u51fa\u4e86\u7eaf\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u65e0\u9700\u5faa\u73af\u6216\u5377\u79ef - \u5f15\u5165\u591a\u5934\u81ea\u6ce8\u610f\u529b\uff08Multi-Head Self-Attention\uff09\u673a\u5236 - \u5728 WMT 2014 \u82f1\u5fb7\u548c\u82f1\u6cd5\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u8fbe\u5230 SOTA</p>"},{"location":"machine-learning/attention-is-all-you-need/#_2","title":"\ud83d\udca1 \u6838\u5fc3\u601d\u60f3","text":""},{"location":"machine-learning/attention-is-all-you-need/#1-self-attention","title":"1. \u81ea\u6ce8\u610f\u529b\u673a\u5236\uff08Self-Attention\uff09","text":"<p>\u901a\u8fc7\u8ba1\u7b97\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u4e0e\u5176\u4ed6\u6240\u6709\u4f4d\u7f6e\u7684\u5173\u8054\u5ea6\uff0c\u6355\u83b7\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff1a</p> \\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\] <p>\u5176\u4e2d \\(Q\\)\uff08Query\uff09\u3001\\(K\\)\uff08Key\uff09\u3001\\(V\\)\uff08Value\uff09\u662f\u8f93\u5165\u7684\u7ebf\u6027\u53d8\u6362\u3002</p>"},{"location":"machine-learning/attention-is-all-you-need/#2-multi-head-attention","title":"2. \u591a\u5934\u6ce8\u610f\u529b\uff08Multi-Head Attention\uff09","text":"<p>\u5e76\u884c\u4f7f\u7528\u591a\u4e2a\u6ce8\u610f\u529b\u5934\uff0c\u6bcf\u4e2a\u5934\u5b66\u4e60\u4e0d\u540c\u7684\u8868\u793a\u5b50\u7a7a\u95f4\uff1a</p> \\[ \\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O \\]"},{"location":"machine-learning/attention-is-all-you-need/#3-positional-encoding","title":"3. \u4f4d\u7f6e\u7f16\u7801\uff08Positional Encoding\uff09","text":"<p>\u7531\u4e8e\u6a21\u578b\u6ca1\u6709\u5faa\u73af\u7ed3\u6784\uff0c\u9700\u8981\u989d\u5916\u6dfb\u52a0\u4f4d\u7f6e\u4fe1\u606f\uff1a</p> \\[ \\begin{align} PE_{(pos, 2i)} &amp;= \\sin(pos / 10000^{2i/d_{model}}) \\\\ PE_{(pos, 2i+1)} &amp;= \\cos(pos / 10000^{2i/d_{model}}) \\end{align} \\]"},{"location":"machine-learning/attention-is-all-you-need/#_3","title":"\ud83c\udfd7\ufe0f \u6a21\u578b\u67b6\u6784","text":"<p>Transformer \u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\uff1a</p> <p>\u7f16\u7801\u5668\uff1a - 6 \u5c42\u5806\u53e0 - \u6bcf\u5c42\u5305\u542b\uff1a\u591a\u5934\u81ea\u6ce8\u610f\u529b + \u524d\u9988\u7f51\u7edc - \u6b8b\u5dee\u8fde\u63a5 + \u5c42\u5f52\u4e00\u5316</p> <p>\u89e3\u7801\u5668\uff1a - 6 \u5c42\u5806\u53e0 - \u6bcf\u5c42\u5305\u542b\uff1a\u63a9\u7801\u591a\u5934\u81ea\u6ce8\u610f\u529b + \u7f16\u7801\u5668-\u89e3\u7801\u5668\u6ce8\u610f\u529b + \u524d\u9988\u7f51\u7edc - \u6b8b\u5dee\u8fde\u63a5 + \u5c42\u5f52\u4e00\u5316</p>"},{"location":"machine-learning/attention-is-all-you-need/#_4","title":"\ud83d\udcca \u5b9e\u9a8c\u7ed3\u679c","text":""},{"location":"machine-learning/attention-is-all-you-need/#_5","title":"\u673a\u5668\u7ffb\u8bd1\u6027\u80fd","text":"\u6a21\u578b WMT'14 EN-DE WMT'14 EN-FR Transformer (big) 28.4 BLEU 41.8 BLEU ConvS2S 25.2 BLEU 40.5 BLEU"},{"location":"machine-learning/attention-is-all-you-need/#_6","title":"\u8bad\u7ec3\u6548\u7387","text":"<ul> <li>\u8bad\u7ec3\u65f6\u95f4\uff1a\u5728 8 \u4e2a P100 GPU \u4e0a\u8bad\u7ec3 3.5 \u5929\uff08base \u6a21\u578b\uff09</li> <li>\u5e76\u884c\u5316\uff1a\u76f8\u6bd4 RNN \u53ef\u4ee5\u66f4\u597d\u5730\u5e76\u884c\u5316\uff0c\u8bad\u7ec3\u901f\u5ea6\u5feb\u6570\u500d</li> </ul>"},{"location":"machine-learning/attention-is-all-you-need/#_7","title":"\ud83e\udd14 \u4e2a\u4eba\u7b14\u8bb0","text":""},{"location":"machine-learning/attention-is-all-you-need/#_8","title":"\u4f18\u52bf","text":"<ol> <li>\u5e76\u884c\u5316\u80fd\u529b\u5f3a\uff1a\u4e0d\u50cf RNN \u9700\u8981\u987a\u5e8f\u5904\u7406\uff0c\u53ef\u4ee5\u5e76\u884c\u8ba1\u7b97\u6240\u6709\u4f4d\u7f6e</li> <li>\u957f\u8ddd\u79bb\u4f9d\u8d56\uff1a\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u76f4\u63a5\u5efa\u6a21\u4efb\u610f\u8ddd\u79bb\u7684\u4f9d\u8d56\u5173\u7cfb</li> <li>\u53ef\u89e3\u91ca\u6027\uff1a\u6ce8\u610f\u529b\u6743\u91cd\u53ef\u4ee5\u53ef\u89c6\u5316\uff0c\u4e86\u89e3\u6a21\u578b\u5173\u6ce8\u54ea\u4e9b\u90e8\u5206</li> </ol>"},{"location":"machine-learning/attention-is-all-you-need/#_9","title":"\u5c40\u9650\u6027","text":"<ol> <li>\u8ba1\u7b97\u590d\u6742\u5ea6\uff1a\u81ea\u6ce8\u610f\u529b\u7684\u590d\u6742\u5ea6\u662f \\(O(n^2)\\)\uff0c\u5e8f\u5217\u8d8a\u957f\u8ba1\u7b97\u91cf\u8d8a\u5927</li> <li>\u4f4d\u7f6e\u7f16\u7801\uff1a\u56fa\u5b9a\u7684\u6b63\u5f26\u4f4d\u7f6e\u7f16\u7801\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u9009\u62e9</li> <li>\u5c0f\u6570\u636e\u96c6\uff1a\u5728\u6570\u636e\u91cf\u8f83\u5c0f\u65f6\uff0cTransformer \u53ef\u80fd\u4e0d\u5982 RNN</li> </ol>"},{"location":"machine-learning/attention-is-all-you-need/#_10","title":"\u5f71\u54cd\u4e0e\u542f\u53d1","text":"<ul> <li>NLP \u9769\u547d\uff1aTransformer \u6210\u4e3a BERT\u3001GPT \u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u57fa\u7840</li> <li>\u8de8\u9886\u57df\u5e94\u7528\uff1aVision Transformer (ViT) \u5c06\u5176\u6210\u529f\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9</li> <li>\u7814\u7a76\u65b9\u5411\uff1a\u5982\u4f55\u964d\u4f4e\u81ea\u6ce8\u610f\u529b\u7684\u590d\u6742\u5ea6\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u65b9\u5411\uff08Linformer\u3001Performer \u7b49\uff09</li> </ul>"},{"location":"machine-learning/attention-is-all-you-need/#_11","title":"\ud83d\udd17 \u76f8\u5173\u8bba\u6587","text":"<ul> <li>BERT: Pre-training of Deep Bidirectional Transformers - \u57fa\u4e8e Transformer \u7684\u9884\u8bad\u7ec3\u6a21\u578b</li> <li>GPT Series - \u751f\u6210\u5f0f\u9884\u8bad\u7ec3 Transformer</li> <li>Vision Transformer (ViT) - Transformer \u5728\u89c6\u89c9\u9886\u57df\u7684\u5e94\u7528</li> </ul>"},{"location":"machine-learning/attention-is-all-you-need/#_12","title":"\ud83d\udccc \u5173\u952e\u4ee3\u7801\u7247\u6bb5","text":"<pre><code>import torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n\n    def forward(self, Q, K, V, mask=None):\n        batch_size = Q.size(0)\n\n        # Linear projections and reshape\n        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n\n        # Scaled dot-product attention\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))\n\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        attention = torch.softmax(scores, dim=-1)\n        output = torch.matmul(attention, V)\n\n        # Concatenate heads and apply final linear\n        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n        return self.W_o(output)\n</code></pre> <p>\u9605\u8bfb\u65e5\u671f\uff1a2024\u5e74 \u7b14\u8bb0\u72b6\u6001\uff1a\u5df2\u5b8c\u6210</p>"},{"location":"nlp/","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406","text":"<p>\u672c\u5206\u7c7b\u6536\u5f55\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u7ecf\u5178\u8bba\u6587\u548c\u524d\u6cbf\u7814\u7a76\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a</p> <ul> <li>\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b</li> <li>\u673a\u5668\u7ffb\u8bd1</li> <li>\u6587\u672c\u751f\u6210</li> <li>\u95ee\u7b54\u7cfb\u7edf</li> <li>\u4fe1\u606f\u62bd\u53d6</li> <li>\u5bf9\u8bdd\u7cfb\u7edf</li> </ul>"},{"location":"nlp/#_2","title":"\ud83d\udcd1 \u8bba\u6587\u5217\u8868","text":""},{"location":"nlp/#_3","title":"\u9884\u8bad\u7ec3\u6a21\u578b","text":"<ul> <li>BERT: Pre-training of Deep Bidirectional Transformers - Google AI, NAACL 2019</li> <li>\u63d0\u51fa\u53cc\u5411\u9884\u8bad\u7ec3 Transformer \u6a21\u578b\uff0c\u5237\u65b0\u591a\u9879 NLP \u4efb\u52a1\u8bb0\u5f55</li> </ul> <p>\u6301\u7eed\u66f4\u65b0\u4e2d...</p>"},{"location":"nlp/bert/","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","text":"<p>\u4f5c\u8005: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova \u673a\u6784: Google AI Language \u4f1a\u8bae: NAACL 2019 \u8bba\u6587\u94fe\u63a5: arXiv:1810.04805</p> <p>BERT \u9884\u8bad\u7ec3 \u53cc\u5411Transformer \u8bed\u8a00\u6a21\u578b</p>"},{"location":"nlp/bert/#_1","title":"\ud83d\udcdd \u6458\u8981","text":"<p>BERT\uff08Bidirectional Encoder Representations from Transformers\uff09\u662f\u4e00\u4e2a\u57fa\u4e8e Transformer \u7684\u53cc\u5411\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u65e0\u6807\u6ce8\u6587\u672c\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5fae\u8c03\uff0cBERT \u5728 11 \u4e2a NLP \u4efb\u52a1\u4e0a\u5237\u65b0\u4e86 SOTA \u8bb0\u5f55\u3002</p> <p>\u4e3b\u8981\u8d21\u732e\uff1a - \u63d0\u51fa\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08MLM\uff09\u5b9e\u73b0\u771f\u6b63\u7684\u53cc\u5411\u9884\u8bad\u7ec3 - \u5f15\u5165\u4e0b\u4e00\u53e5\u9884\u6d4b\uff08NSP\uff09\u4efb\u52a1\u5b66\u4e60\u53e5\u5b50\u5173\u7cfb - \u5728\u591a\u4e2a NLP \u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347</p>"},{"location":"nlp/bert/#_2","title":"\ud83d\udca1 \u6838\u5fc3\u601d\u60f3","text":""},{"location":"nlp/bert/#1","title":"1. \u53cc\u5411\u4e0a\u4e0b\u6587\u5efa\u6a21","text":"<p>\u4e0e\u4f20\u7edf\u7684\u5355\u5411\u8bed\u8a00\u6a21\u578b\uff08\u5982 GPT\uff09\u4e0d\u540c\uff0cBERT \u901a\u8fc7\u63a9\u7801\u8bed\u8a00\u6a21\u578b\u540c\u65f6\u5229\u7528\u5de6\u53f3\u4e0a\u4e0b\u6587\uff1a</p> <pre><code>\u4f20\u7edf LM:  The cat [sat] on the mat\n           \u2190\u2190\u2190\u2190\u2190\nGPT:      The cat [sat] on the mat\n           \u2192\u2192\u2192\u2192\u2192\nBERT:     The cat [MASK] on the mat\n           \u2190\u2190\u2190\u2192\u2192\u2192\u2192\n</code></pre>"},{"location":"nlp/bert/#2-masked-language-model","title":"2. \u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08Masked Language Model\uff09","text":"<p>\u968f\u673a\u63a9\u76d6\u8f93\u5165\u4e2d 15% \u7684\u8bcd\uff0c\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u88ab\u63a9\u76d6\u7684\u8bcd\uff1a</p> <ul> <li>80% \u66ff\u6362\u4e3a <code>[MASK]</code></li> <li>10% \u66ff\u6362\u4e3a\u968f\u673a\u8bcd</li> <li>10% \u4fdd\u6301\u4e0d\u53d8</li> </ul> <p>\u76ee\u6807\uff1a\u6700\u5927\u5316\u88ab\u63a9\u76d6\u8bcd\u7684\u6761\u4ef6\u6982\u7387</p>"},{"location":"nlp/bert/#3-next-sentence-prediction","title":"3. \u4e0b\u4e00\u53e5\u9884\u6d4b\uff08Next Sentence Prediction\uff09","text":"<p>\u7ed9\u5b9a\u53e5\u5b50\u5bf9 (A, B)\uff0c\u9884\u6d4b B \u662f\u5426\u662f A \u7684\u4e0b\u4e00\u53e5\uff1a</p> <pre><code>Input:  [CLS] Sentence A [SEP] Sentence B [SEP]\nLabel:  IsNext / NotNext\n</code></pre>"},{"location":"nlp/bert/#_3","title":"\ud83c\udfd7\ufe0f \u6a21\u578b\u67b6\u6784","text":"<p>BERT \u57fa\u4e8e Transformer \u7f16\u7801\u5668\uff0c\u6709\u4e24\u4e2a\u7248\u672c\uff1a</p> \u6a21\u578b \u5c42\u6570 \u9690\u85cf\u7ef4\u5ea6 \u6ce8\u610f\u529b\u5934 \u53c2\u6570\u91cf BERT-Base 12 768 12 110M BERT-Large 24 1024 16 340M"},{"location":"nlp/bert/#_4","title":"\u8f93\u5165\u8868\u793a","text":"<p>\u4e09\u79cd\u5d4c\u5165\u6c42\u548c\uff1a</p> <pre><code>Token Embeddings:    [CLS] my dog is cute [SEP] he likes play ##ing [SEP]\nSegment Embeddings:  E_A   E_A E_A E_A E_A E_A  E_B  E_B   E_B  E_B   E_B\nPosition Embeddings: E_0   E_1 E_2 E_3 E_4 E_5  E_6  E_7   E_8  E_9   E_10\n</code></pre>"},{"location":"nlp/bert/#_5","title":"\u7279\u6b8a\u6807\u8bb0","text":"<ul> <li><code>[CLS]</code>\uff1a\u5e8f\u5217\u5206\u7c7b\u6807\u8bb0\uff0c\u5176\u8f93\u51fa\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1</li> <li><code>[SEP]</code>\uff1a\u53e5\u5b50\u5206\u9694\u7b26</li> <li><code>[MASK]</code>\uff1a\u63a9\u7801\u6807\u8bb0</li> </ul>"},{"location":"nlp/bert/#_6","title":"\ud83d\udcca \u5b9e\u9a8c\u7ed3\u679c","text":""},{"location":"nlp/bert/#glue","title":"GLUE \u57fa\u51c6\u6d4b\u8bd5","text":"\u4efb\u52a1 \u6307\u6807 BERT-Base BERT-Large \u4e4b\u524d SOTA MNLI Acc 84.6/83.4 86.7/85.9 80.5/80.1 QQP F1 71.2 72.1 66.1 QNLI Acc 90.5 92.7 87.4 SST-2 Acc 93.5 94.9 93.2 CoLA Matthews Corr 52.1 60.5 35.0"},{"location":"nlp/bert/#squad","title":"SQuAD \u95ee\u7b54","text":"\u6a21\u578b SQuAD 1.1 F1 SQuAD 2.0 F1 BERT-Base 88.5 76.3 BERT-Large 93.2 83.1 \u4eba\u7c7b\u8868\u73b0 91.2 86.8 <p>BERT-Large \u5728 SQuAD 1.1 \u4e0a\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\uff01</p>"},{"location":"nlp/bert/#conll-2003-ner","title":"\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08CoNLL-2003 NER\uff09","text":"\u6a21\u578b F1 \u4e4b\u524d SOTA 92.6 BERT-Large 92.8"},{"location":"nlp/bert/#_7","title":"\ud83e\udd14 \u4e2a\u4eba\u7b14\u8bb0","text":""},{"location":"nlp/bert/#_8","title":"\u5173\u952e\u8bbe\u8ba1","text":"<ol> <li>WordPiece \u5206\u8bcd\uff1a\u5904\u7406\u672a\u767b\u5f55\u8bcd\uff0c\u51cf\u5c0f\u8bcd\u8868\u5927\u5c0f</li> <li>Segment Embeddings\uff1a\u533a\u5206\u53e5\u5b50\u5bf9\u4e2d\u7684\u4e0d\u540c\u53e5\u5b50</li> <li>\u9884\u8bad\u7ec3 + \u5fae\u8c03\u8303\u5f0f\uff1a\u901a\u7528\u9884\u8bad\u7ec3 \u2192 \u4efb\u52a1\u7279\u5b9a\u5fae\u8c03</li> </ol>"},{"location":"nlp/bert/#_9","title":"\u4e3a\u4ec0\u4e48\u6709\u6548\uff1f","text":"<ul> <li>\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff1a\u4ece BooksCorpus (800M \u8bcd) + Wikipedia (2,500M \u8bcd) \u5b66\u4e60\u901a\u7528\u8bed\u8a00\u8868\u793a</li> <li>\u53cc\u5411\u5efa\u6a21\uff1a\u6bd4\u5355\u5411\u6a21\u578b\u80fd\u6355\u83b7\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587</li> <li>\u6df1\u5ea6 Transformer\uff1a\u5f3a\u5927\u7684\u8868\u793a\u5b66\u4e60\u80fd\u529b</li> </ul>"},{"location":"nlp/bert/#_10","title":"\u5c40\u9650\u6027","text":"<ol> <li>\u8ba1\u7b97\u6210\u672c\u9ad8\uff1a\u9884\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff084-16 TPU\uff0c\u51e0\u5929\u65f6\u95f4\uff09</li> <li>NSP \u4efb\u52a1\u4e89\u8bae\uff1a\u540e\u7eed\u7814\u7a76\uff08RoBERTa\uff09\u8868\u660e NSP \u53ef\u80fd\u4e0d\u5fc5\u8981</li> <li>[MASK] \u4e0d\u4e00\u81f4\uff1a\u9884\u8bad\u7ec3\u7528 [MASK]\uff0c\u4f46\u5fae\u8c03\u65f6\u6ca1\u6709</li> <li>\u6700\u5927\u957f\u5ea6\u9650\u5236\uff1a512 tokens \u9650\u5236\u4e86\u957f\u6587\u672c\u5904\u7406</li> </ol>"},{"location":"nlp/bert/#_11","title":"\u540e\u7eed\u53d1\u5c55","text":"<ul> <li>RoBERTa\uff1a\u79fb\u9664 NSP\uff0c\u52a8\u6001\u63a9\u7801\uff0c\u66f4\u5927\u6279\u6b21</li> <li>ALBERT\uff1a\u53c2\u6570\u5171\u4eab\uff0c\u53e5\u5b50\u987a\u5e8f\u9884\u6d4b\uff08SOP\uff09</li> <li>ELECTRA\uff1a\u5224\u522b\u5f0f\u9884\u8bad\u7ec3\uff0c\u66f4\u9ad8\u6548</li> <li>T5\uff1a\u7edf\u4e00 text-to-text \u6846\u67b6</li> <li>GPT-3/ChatGPT\uff1a\u5927\u89c4\u6a21\u751f\u6210\u5f0f\u9884\u8bad\u7ec3</li> </ul>"},{"location":"nlp/bert/#_12","title":"\u5e94\u7528\u6280\u5de7","text":"<p>\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\uff1a - \u5206\u7c7b\u4efb\u52a1\uff1a\u4f7f\u7528 [CLS] \u8f93\u51fa + \u7ebf\u6027\u5c42 - \u5e8f\u5217\u6807\u6ce8\uff1a\u6bcf\u4e2a token \u8f93\u51fa + \u7ebf\u6027\u5c42 - \u95ee\u7b54\u4efb\u52a1\uff1a\u9884\u6d4b\u7b54\u6848\u8d77\u59cb\u548c\u7ed3\u675f\u4f4d\u7f6e</p> <p>\u8d85\u53c2\u6570\uff1a - Batch size: 16, 32 - Learning rate: 5e-5, 3e-5, 2e-5 - Epochs: 2-4</p>"},{"location":"nlp/bert/#_13","title":"\ud83d\udd17 \u76f8\u5173\u8bba\u6587","text":"<ul> <li>Attention Is All You Need - Transformer \u67b6\u6784\u57fa\u7840</li> <li>ELMo: Deep contextualized word representations - \u65e9\u671f\u7684\u53cc\u5411\u9884\u8bad\u7ec3</li> <li>GPT: Improving Language Understanding by Generative Pre-Training - \u5355\u5411\u9884\u8bad\u7ec3</li> <li>RoBERTa: A Robustly Optimized BERT Pretraining Approach - BERT \u6539\u8fdb</li> <li>ELECTRA: Pre-training Text Encoders as Discriminators - \u66f4\u9ad8\u6548\u7684\u9884\u8bad\u7ec3</li> </ul>"},{"location":"nlp/bert/#_14","title":"\ud83d\udccc \u5173\u952e\u4ee3\u7801\u7247\u6bb5","text":"<pre><code>from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5206\u8bcd\u5668\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# \u51c6\u5907\u8f93\u5165\ntext = \"BERT is a powerful pre-trained model.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n\n# \u524d\u5411\u4f20\u64ad\noutputs = model(**inputs)\nlogits = outputs.logits\npredictions = torch.argmax(logits, dim=-1)\n\nprint(f\"Predictions: {predictions}\")\n</code></pre>"},{"location":"nlp/bert/#_15","title":"\u5fae\u8c03\u793a\u4f8b","text":"<pre><code>from transformers import BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\ndataset = load_dataset('glue', 'sst2')\n\n# \u51c6\u5907\u6a21\u578b\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# \u8bad\u7ec3\u914d\u7f6e\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    learning_rate=2e-5,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n)\n\n# \u8bad\u7ec3\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset['train'],\n    eval_dataset=dataset['validation'],\n)\n\ntrainer.train()\n</code></pre> <p>\u9605\u8bfb\u65e5\u671f\uff1a2024\u5e74 \u7b14\u8bb0\u72b6\u6001\uff1a\u5df2\u5b8c\u6210</p>"}]}